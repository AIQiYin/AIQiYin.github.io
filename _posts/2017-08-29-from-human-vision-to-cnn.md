---
layout: post
title: "人类视觉分类是怎样的"
description: ""
category: mix
tags: []
modify: 2017-08-29 18:23:19
---

update: 2017-08-29


今天在学习opencv的时候频频想到人类视觉，因为大概里面的很多方法都是从人类视觉的启发而来的，而我也特别喜欢这种启发式的灵感，对理解新知识很有帮助，总有一种柳暗花明又一村的脑洞大开。自己也常常由这些huristic的想法发现新的解决方法，当时都觉得自己很牛逼，会不会是一个历史上伟大的创举？心中窃喜，但是往往一查就发现前人早把这些做过了，做的更多更好，好吧，我承认科研就是有这么多的坑啊。。。

今天大概查了下人类视觉的神经有好几种，主要是视锥细胞和视杆细胞，分别600万和1.25亿左右，视锥细胞起主要作用。如果以这个来看，现在的相机系统已经达到并超越了。为什么要提这个，因为我觉得现在的训练图像像素都是很小的，深度学习等算法的原理虽是类比神经元结构，但配置上如果相差很大，那就可能永远模拟不到人眼的功能，因为只有更大的系统才能模拟小系统。就像色盲或色弱是分别不了一些物体的，又假设，如果把一个小孩的眼睛得了怪病分辨率奇低或放在一个满是模糊物体的世界里，也是无法正常识别我们现在正常人识别的东西的。

另外，视觉细胞的数量足够多对于我们将世界看作是连续的一个原因，这样可以将低于分辨精度最小的距离当作连续的结果就不会影响到事实，不造成我们对这个世界的认识偏差，这和经典连续与量子离散的过程相反。虽然我们认为世界是连续的，但实际上我们的神经细胞终究是离散的，奇怪的是我们自身是完全没意识到这个问题，从我们的眼睛成像到大脑，看到的永远是连续的图像！这个很神奇，我想到的结论是大脑中枢系统并没有接触到最原始的数据而是经过大量处理后的结果，这个结果里就有连续化的作用！这也是我最近一直在思考图像识别该如何去将像素点连续化的问题，这也是从人眼的得出的启发。至于人眼中从最前端的神经元激发如何一步步变换到连续的结果，中间的过程有多少，又有多复杂这真值得思考。

cnn的卷即过程看起来是一种上述过程的类似实现，但无从考究，我想说的另一点是，有时这个过程我们并不一定要去重构，可以直接使用启发后的结果当作输入信息，不断的发掘需要的变换，这也是opencv主要做的事，当然这个工作有可能非常大永远也不能完全列举出所需的要素。

所以大家现在更倾向于深度学习，因为这很像神经元链接结构，只要网络足够大足够深，最stupid的方式，但确是有可能模拟到人眼的那个变换过程。而后我又觉得现在的深度学习从架构上来看还是和人的识别过程有点区别，或说深度学习的架构太simple了。它将所有分类都当作one-hot，如果把对人脑而言每一类都是一个神经元输出，那这个世界的分类太多了，人脑细胞虽接近千亿，但除去其他的任务所需的神经元后最终能给分类的神经元怕是不及亿个，那人类的分类能力就大大受限了。我想了下，有一种解决方案，那就是组合结构，最终的输出是由大量基层分类因子决定的，可以实现2^n级分类，一层或多层的树结构，一层的就类似cnn最后一层的全连接层，这可能可以作为cnn最后一层是全连接层的一个直观解释吧（当然可能前人已经是这么想的了），也同样说明倒数第二层的单元数是可以小于类别数的了。

而多层的树结构更接近我们人类的思考过程，所以我总感觉人眼前端结构是用一种我们不能意识到的处理方式给我们提供了大量基本分类单元后，再由大脑执行决策系统，而这个决策系统也是根据任务目标临时搭建不同的系统，这又像迁移学习的过程。

大量基本分类单元的另一个佐证可以以猫和狗举例，猫和狗我们一般都是直接分成不同的类，但是否我们给它们分成不同的类就代表它们完全不同呢，非也！这个世界可能就没有绝对的分类，我们无法给不同做一个绝对真理性的定义，所以这都是相对的，而且是因为人类的处理能力受限所导致分成类别以简单处理信息。

深究的话，猫和狗身上有着绝大部分特征是相似或相同的，而我们是从所有的相同和不同的细节单元里去做决策树分类的，当然这是原始的，可能是小孩的阶段，但后来我们长大了就直接建立起了固定结构以至于我们又忘了其中的过程，就像意识不到视觉神经到大脑的处理过程。
